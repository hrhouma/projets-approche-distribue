# **Quiz 2 : Choisir la bonne méthode**

### **Question 1 :**

Une équipe de marketing génère des rapports hebdomadaires à partir de données stables dans Amazon Athena. Comment peuvent-ils optimiser les performances sans réexécuter la même requête ?

1. Modifier les requêtes chaque semaine.
2. Activer la réutilisation des résultats des requêtes dans Amazon Athena.
3. Limiter la taille des données analysées à 1 Go.
4. Utiliser Amazon Redshift pour stocker les données de vente.

---

### **Question 2 :**

Votre entreprise souhaite analyser des données sensibles stockées dans Amazon RDS sans complexité. Quelle méthode est la plus simple ?

1. Analyser directement dans RDS avec des contrôles d'accès manuels.
2. Transférer les données vers Amazon Redshift et utiliser des groupes de sécurité.
3. Utiliser AWS Lake Formation pour gérer les permissions et faciliter l’analyse.
4. Migrer les données vers Amazon S3 et les analyser avec Amazon Athena.

---

### **Question 3 :**

Une équipe ajoute régulièrement des données à Amazon S3, mais les nouvelles partitions ne s'affichent pas dans Amazon Athena. Que doivent-ils faire ?

1. Exécuter **MSCK REPAIR TABLE** dans Athena.
2. Mettre à jour manuellement les partitions.
3. Utiliser un AWS Glue Crawler pour détecter les nouvelles partitions.
4. Créer une nouvelle table à chaque fois avec les partitions mises à jour.

---

### **Question 4 :**

Vous devez valider la qualité des données avant de les traiter dans AWS Glue. Quelle méthode simple pouvez-vous utiliser pour automatiser cela ?

1. Utiliser AWS Glue Data Quality pour surveiller et valider les données.
2. Interroger manuellement les données avec Amazon Athena.
3. Utiliser Amazon EMR pour créer des scripts de validation personnalisés.
4. Configurer AWS Data Pipeline avec des scripts de validation.

---

### **Question 5 :**

Une équipe d'analyse veut accélérer l'exécution de requêtes fréquentes sur Amazon Athena. Quelle approche est la meilleure ?

1. Modifier chaque requête à chaque exécution.
2. Activer la réutilisation des résultats de requêtes pour gagner du temps.
3. Limiter la taille des données scannées par requête.
4. Exécuter les requêtes via Amazon Redshift.

---

### **Question 6 :**

Vous avez des données de vente stockées dans Amazon S3. Quelle option vous permet d’interroger ces données efficacement sans dupliquer les informations ?

1. Utiliser Amazon Athena pour interroger directement les données.
2. Déplacer les données vers Amazon RDS pour les analyser.
3. Migrer les données vers Redshift pour une meilleure performance.
4. Créer une copie des données sur un serveur local.

---

### **Question 7 :**

Une équipe doit surveiller la qualité des données stockées dans Amazon S3. Quelle solution simple peut-elle utiliser pour automatiser cette surveillance ?

1. Utiliser AWS Glue Data Quality pour surveiller la qualité des données.
2. Configurer un script manuel pour vérifier les données.
3. Utiliser Amazon EMR pour traiter les données avec des scripts personnalisés.
4. Configurer AWS Data Pipeline pour gérer les tâches de surveillance.

---

### **Question 8 :**

Une équipe souhaite exécuter des requêtes sur plusieurs sources de données (S3, DynamoDB, Aurora) sans déplacer les données. Quelle option AWS est la plus simple ?

1. Utiliser Amazon Athena Federated Query.
2. Migrer toutes les données vers un lac de données S3.
3. Configurer un serveur pour copier les données.
4. Utiliser Amazon Redshift Spectrum pour interroger les données.

---

### **Question 9 :**

Une équipe doit analyser les données des patients dans un lac de données Amazon S3. Quel service permet de gérer cela facilement ?

1. Utiliser Amazon Athena pour interroger les données directement.
2. Déplacer les données vers un entrepôt Amazon Redshift pour une analyse plus rapide.
3. Utiliser Amazon RDS pour interroger les données des patients.
4. Utiliser Amazon DynamoDB pour stocker et analyser les données des patients.

---

### **Question 10 :**

Une entreprise veut combiner des données de différentes sources pour créer des rapports sans déplacer les données vers S3. Quelle est la meilleure solution ?

1. Utiliser Amazon Athena Federated Query pour interroger les différentes sources de données.
2. Migrer toutes les données vers Amazon Redshift pour une meilleure analyse.
3. Utiliser AWS Glue pour transformer et déplacer les données vers S3.
4. Configurer un pipeline d’intégration manuelle.

---

### **Question 11 :**

Votre équipe a des données sensibles sur Amazon RDS. Quel service AWS permet de gérer les permissions et faciliter l'accès aux données ?

1. Utiliser AWS IAM pour gérer les permissions d'accès.
2. Migrer les données vers Amazon S3 et utiliser des rôles IAM.
3. Configurer des groupes de sécurité sur Amazon Redshift.
4. Utiliser AWS Lake Formation pour gérer les permissions de manière granulaire.

---

### **Question 12 :**

Une équipe doit ajouter régulièrement des données à un lac de données partitionné sur Amazon S3. Quelle méthode garantit que les nouvelles partitions sont disponibles dans Athena ?

1. Utiliser un AWS Glue Crawler pour détecter les nouvelles partitions.
2. Mettre à jour manuellement chaque nouvelle partition.
3. Exécuter un script de synchronisation à chaque ajout de données.
4. Réduire la taille des partitions pour qu'elles soient visibles automatiquement.

---

### **Question 13 :**

Votre équipe d'analyse utilise Amazon Athena pour interroger des données sur S3. Comment peuvent-ils améliorer les performances des requêtes sans déplacer les données ?

1. Convertir les données en format Parquet ou ORC pour des requêtes plus rapides.
2. Déplacer les données vers Amazon Redshift.
3. Modifier les partitions manuellement pour optimiser les requêtes.
4. Créer un index des données pour accélérer la récupération.

---

### **Question 14 :**

Une entreprise souhaite automatiser le traitement de ses données stockées sur Amazon S3. Quelle est la meilleure option pour automatiser ce processus ?

1. Configurer des travaux ETL dans AWS Glue pour automatiser le traitement.
2. Migrer les données vers un entrepôt de données.
3. Utiliser des scripts manuels pour gérer le traitement des données.
4. Configurer un pipeline AWS Data Pipeline pour automatiser les tâches.

---

### **Question 15 :**

Votre équipe d'ingénierie souhaite valider et surveiller la qualité des données dans un pipeline ETL. Quel service AWS est le plus approprié pour cela ?

1. Utiliser AWS Glue Data Quality pour automatiser la validation.
2. Utiliser Amazon Athena pour exécuter manuellement des requêtes de validation.
3. Créer un script personnalisé avec Amazon EMR.
4. Configurer AWS Data Pipeline pour gérer et surveiller les données.

---

### **Question 16 :**

Une équipe doit exécuter des requêtes SQL sur des données provenant de plusieurs services AWS (S3, DynamoDB, RDS). Quelle solution peut-elle utiliser pour éviter de déplacer les données ?

1. Utiliser Amazon Athena Federated Query pour exécuter des requêtes SQL.
2. Migrer les données vers Amazon Redshift pour une analyse plus rapide.
3. Utiliser AWS Glue pour transformer les données avant de les analyser.
4. Créer une application personnalisée pour combiner les données des services.

---

### **Question 17 :**

Une entreprise stocke ses données dans un lac de données sur S3 et utilise Amazon Athena pour les analyser. Comment peuvent-ils réduire le temps de réponse des requêtes ?

1. Utiliser un format de stockage comme Parquet ou ORC.
2. Déplacer les données vers Amazon RDS pour une meilleure performance.
3. Créer une indexation des données sur Amazon S3.
4. Exécuter des requêtes plus petites pour réduire le temps de réponse.

---

### **Question 18 :**

Une entreprise souhaite réduire le coût et améliorer la rapidité des requêtes exécutées dans Amazon Athena. Quelle fonctionnalité simple peuvent-ils utiliser ?

1. Activer la réutilisation des résultats de requêtes dans Athena.
2. Migrer les données vers Amazon RDS pour une meilleure performance.
3. Exécuter manuellement des requêtes plus petites.
4. Limiter la taille des données scannées dans chaque requête.

---

### **Question 19 :**

Une équipe d'analyse utilise Amazon Athena pour interroger des données sur S3, mais les nouvelles partitions ne s'affichent pas dans les résultats. Que doivent-ils faire ?

1. Exécuter **MSCK REPAIR TABLE** dans Athena.
2. Mettre à jour manuellement les partitions.
3. Utiliser un AWS Glue Crawler pour détecter automatiquement les nouvelles partitions.
4. Créer une nouvelle table pour chaque nouvelle partition.

---

### **Question 20 :**

Une entreprise souhaite interroger des données provenant de plusieurs sources sans déplacer les données. Quelle solution AWS est la plus appropriée ?

1. Utiliser Amazon Athena Federated Query pour interroger les données de différentes sources.
2. Déplacer les données vers un entrepôt de données centralisé.
3. Utiliser AWS Glue pour transformer les données avant de les analyser.
4. Créer un système personnalisé pour interroger les différentes sources.

