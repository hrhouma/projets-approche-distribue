# **Partie 02 - Question de développement**

---

*À partir des différents travaux de conception de pipelines de données listés ci-dessous, choisissez l’un des travaux et décrivez-le en détail. Vous devrez répondre aux points suivants :*

### Liste des travaux :

1. **[Travail 1](https://medium.com/@dogukannulu/aws-cloud-data-engineering-end-to-end-project-aws-glue-etl-job-s3-apache-spark-967d6ebe1d88)** : Pipeline avec AWS Glue ETL, S3, et Apache Spark.
2. **[Travail 2](https://medium.com/@dogukannulu/creating-quicksight-dashboards-using-amazon-redshift-and-athena-b503a8f937bf)** : Création de tableaux de bord QuickSight avec Redshift et Athena.
3. **[Travail 3](https://medium.com/@ifeanyiobiana/data-analysis-made-easy-s3-aws-glue-athena-and-quicksight-22125e36b3ae)** : Analyse de données avec S3, AWS Glue, Athena, et QuickSight.
4. **[Travail 4](https://blog.det.life/how-to-build-a-data-pipeline-with-aws-glue-and-terraform-ac1ace165d29)** : Construction d’un pipeline de données avec AWS Glue et Terraform.
5. **[Travail 5](https://www.cloudthat.com/resources/blog/building-real-time-data-pipelines-with-aws-glue)** : Construction de pipelines de données en temps réel avec AWS Glue.
6. **[Travail 6](https://aws.amazon.com/fr/blogs/big-data/build-and-orchestrate-etl-pipelines-using-amazon-athena-and-aws-step-functions/)** : Orchestration des pipelines ETL avec Amazon Athena et AWS Step Functions.
7. **[Travail 7](https://medium.com/@yaroslavzhbankov/architecting-scalable-data-analytics-harnessing-aws-athena-glue-s3-lambda-and-api-gateway-5e991d46c273)** : Architecture analytique évolutive avec AWS Athena, Glue, S3, Lambda et API Gateway.

# **Instructions pour répondre :**

1. **Description du pipeline choisi** :
   - Expliquez les étapes clés du pipeline de données que vous avez choisi, de l'acquisition des données jusqu'à leur transformation, stockage, et analyse/visualisation.

2. **Justification des choix de services AWS** :
   - Décrivez les services AWS utilisés dans le pipeline (ex. S3, Glue, Athena, Lambda, etc.). Pourquoi ces services spécifiques ont-ils été choisis pour chaque étape du pipeline ? En quoi facilitent-ils l'ingestion, le traitement, et l'analyse des données ?

3. **Critique et proposition d'amélioration** :
   - Critiquez les choix effectués. Estimez-vous que les services AWS sélectionnés sont les meilleurs pour cette architecture ? Justifiez vos réponses.
   - **Proposez une alternative** : Faites des recherches sur des solutions alternatives ou des services AWS similaires qui pourraient être utilisés pour remplacer certains services dans ce pipeline (par exemple, remplacer **Athena** par **Redshift Spectrum**, ou **AWS Glue** par un autre outil ETL).
   - Expliquez en quoi votre proposition rendrait le pipeline plus performant, plus rentable ou plus simple à maintenir.

4. **Facilités et complexités** :
   - Identifiez les éléments du pipeline que vous jugez simples à mettre en place ou à maintenir, ainsi que ceux qui semblent plus complexes.
   - **Recherche complémentaire** : Proposez des moyens de réduire cette complexité (recherche d'alternatives plus faciles à gérer, automatisation, etc.). L'objectif ici est de chercher et de critiquer en vue de proposer des solutions plus efficaces ou simples.

### **Conclusion** :
- Donnez une opinion personnelle sur l’efficacité globale du pipeline choisi, à la lumière de vos recherches et de vos critiques. Quelles seraient vos recommandations finales pour optimiser ou adapter ce pipeline à d'autres besoins ou contextes ?

